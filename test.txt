cv::Mat CameraSystemExtrinsicCalibUseBoard::CalcCameraSystemExtrinsic(
    cv::Mat &img, Points_Image_World &points_of_image_world,
    const std::string &img_file) {
  std::vector<cv::Point2f> img_points = points_of_image_world.points_image;
  std::vector<cv::Point2f> world_points = points_of_image_world.points_world;
  // cv::Mat img_ = img.clone();
  cv::Mat img_ = cv::imread(img_file, CV_LOAD_IMAGE_GRAYSCALE);
  // prepare opengv data
  opengv::bearingVectors_t bearings;
  opengv::points_t points3D;
  for (size_t i = 0; i < img_points.size(); i++) {
    cv::Point2f point2d = img_points[i];
    cv::Point2f worldpoint = world_points[i];
    cv::Point3f p3 = camera_param_->Camera2World(
        cv::Point2f(point2d.x, point2d.y + float(image_row_offset)));
    bearings.push_back(opengv::bearingVector_t(p3.x, p3.y, p3.z));
    points3D.push_back(opengv::point_t(worldpoint.x, worldpoint.y, 0));
  }
  cv::Mat Twc;
  cv::Mat Twc_nonlinear;
  Optimizer::CalculateTwc(Twc, Twc_nonlinear, bearings, points3D);
  cv::Mat Tcw = Twc_nonlinear.inv();
  cv::Mat Rcw = Tcw.rowRange(0, 3).colRange(0, 3);
  cv::Mat tcw = Tcw.rowRange(0, 3).col(3);
  ProjectChessboardPoints(img, Tcw, world_points, camera_param_,
                          cv::Scalar(0, 255, 0));
  ProjectChessboardPoints(img, Twc_nonlinear.inv(), world_points, camera_param_,
                          cv::Scalar(0, 0, 255));
  cv::imshow("ChessBoard Points Reprojection", img);
  cv::waitKey(0);
  
  
#include <opencv2/opencv.hpp>
#include <opengv/absolute_pose/CentralAbsoluteAdapter.hpp>
#include <opengv/absolute_pose/methods.hpp>
#include <opengv/sac/Ransac.hpp>
#include <opengv/sac_problems/absolute_pose/AbsolutePoseSacProblem.hpp>

void Optimizer::CalculateTwc(cv::Mat &Twc, cv::Mat &Twc_nonlinear,
                             opengv::bearingVectors_t bearings,
                             opengv::points_t points3D) {

  size_t iterations = 50;

  opengv::absolute_pose::CentralAbsoluteAdapter adapter(bearings, points3D);
  opengv::sac::Ransac<
      opengv::sac_problems::absolute_pose::AbsolutePoseSacProblem>
      ransac;
  std::shared_ptr<opengv::sac_problems::absolute_pose::AbsolutePoseSacProblem>
      absposeproblem_ptr(
          new opengv::sac_problems::absolute_pose::AbsolutePoseSacProblem(
              adapter, opengv::sac_problems::absolute_pose::
                           AbsolutePoseSacProblem::KNEIP));

  std::vector<int> inliers;

  ransac.sac_model_ = absposeproblem_ptr;
  ransac.threshold_ = 0.02;
  ransac.max_iterations_ = 200;
  ransac.computeModel();
  inliers = ransac.inliers_;
  opengv::transformation_t trafo = ransac.model_coefficients_;

  std::cout << " Kneip PnP result : " << std::endl;
  std::cout << trafo << std::endl;

  Twc = cv::Mat::eye(4, 4, CV_32F);
  for (int i = 0; i < 3; i++) {
    for (int j = 0; j < 4; j++) {
      Twc.at<float>(i, j) = (float)trafo(i, j);
    }
  }

  // use nonlinear optimization to get better result
  opengv::translation_t position;
  opengv::rotation_t rotation;
  for (int i = 0; i < 3; i++) {
    position(i) = trafo(i, 3);
    for (int j = 0; j < 3; j++) {
      rotation(i, j) = trafo(i, j);
    }
  }
  adapter.setR(rotation);
  adapter.sett(position);

  std::cout << rotation << std::endl;
  std::cout << position << std::endl;
  for (int i = 0; i < iterations; i++)
    trafo = opengv::absolute_pose::optimize_nonlinear(adapter);
  std::cout << " nonlinear optimization result : " << std::endl;
  std::cout << trafo << std::endl;

  Twc_nonlinear = cv::Mat::eye(4, 4, CV_32F);
  for (int i = 0; i < 3; i++) {
    for (int j = 0; j < 4; j++) {
      Twc_nonlinear.at<float>(i, j) = (float)trafo(i, j);
    }
  }
}
